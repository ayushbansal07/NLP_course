{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.parse.transitionparser import TransitionParser, Configuration, Transition\n",
    "from nltk.parse import DependencyGraph\n",
    "from nltk.parse import DependencyEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_TRAIN_FILE = \"UD_Hindi/hi-ud-train\"\n",
    "BASE_TEST_FILE = \"UD_Hindi/hi-ud-test\"\n",
    "EXTENTION = \".conllu\"\n",
    "EXTRA_SUFFIX = \"-extra\"\n",
    "REMOVE_SUFFIX = \"-rem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create data for origignal data + column 10 features\n",
    "#Train Data\n",
    "with open(BASE_TRAIN_FILE+EXTENTION,'r') as f, open(BASE_TRAIN_FILE+EXTRA_SUFFIX+EXTENTION,'w') as f2 :\n",
    "    for line in f.read().split(\"\\n\\n\"):\n",
    "        for element in line.split(\"\\n\"):\n",
    "            feats = element.split(\"\\t\")\n",
    "            if len(feats) > 9:\n",
    "                if feats[5] != \"_\":\n",
    "                    feats[5] += \"|\" + feats[9]\n",
    "                else:\n",
    "                    feats[5] = feats[9]\n",
    "            f2.write('\\t'.join(feats))\n",
    "            f2.write(\"\\n\")\n",
    "            \n",
    "        f2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create data for origignal data + column 10 features\n",
    "#Test Data\n",
    "with open(BASE_TEST_FILE+EXTENTION,'r') as f, open(BASE_TEST_FILE+EXTRA_SUFFIX+EXTENTION,'w') as f2 :\n",
    "    for line in f.read().split(\"\\n\\n\"):\n",
    "        for element in line.split(\"\\n\"):\n",
    "            feats = element.split(\"\\t\")\n",
    "            if len(feats) > 9:\n",
    "                if feats[5] != \"_\":\n",
    "                    feats[5] += \"|\" + feats[9]\n",
    "                else:\n",
    "                    feats[5] = feats[9]\n",
    "            f2.write('\\t'.join(feats))\n",
    "            f2.write(\"\\n\")\n",
    "            \n",
    "        f2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data without morphological features\n",
    "#Train Data\n",
    "with open(BASE_TRAIN_FILE+EXTENTION,'r') as f, open(BASE_TRAIN_FILE+REMOVE_SUFFIX+EXTENTION,'w') as f2 :\n",
    "    for line in f.read().split(\"\\n\\n\"):\n",
    "        for element in line.split(\"\\n\"):\n",
    "            feats = element.split(\"\\t\")\n",
    "            if len(feats) > 5:\n",
    "                feats[5] = \"_\"\n",
    "            f2.write('\\t'.join(feats))\n",
    "            f2.write(\"\\n\")\n",
    "            \n",
    "        f2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create data without morphological features\n",
    "#Test Data\n",
    "with open(BASE_TEST_FILE+EXTENTION,'r') as f, open(BASE_TEST_FILE+REMOVE_SUFFIX+EXTENTION,'w') as f2 :\n",
    "    for line in f.read().split(\"\\n\\n\"):\n",
    "        for element in line.split(\"\\n\"):\n",
    "            feats = element.split(\"\\t\")\n",
    "            if len(feats) > 5:\n",
    "                feats[5] = \"_\"\n",
    "            f2.write('\\t'.join(feats))\n",
    "            f2.write(\"\\n\")\n",
    "            \n",
    "        f2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tempfile\n",
    "from os import remove\n",
    "import pickle\n",
    "\n",
    "class CustomTransitionParser(TransitionParser):\n",
    "    def __init__(self, algorithm, training_classifier=\"svm\"):\n",
    "        TransitionParser.__init__(self, algorithm)\n",
    "        self.training_classifier = training_classifier\n",
    "    \n",
    "    def train(self, depgraphs, modelfile, verbose=True):\n",
    "        \"\"\"\n",
    "        :param depgraphs : list of DependencyGraph as the training data\n",
    "        :type depgraphs : DependencyGraph\n",
    "        :param modelfile : file name to save the trained model\n",
    "        :type modelfile : str\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            input_file = tempfile.NamedTemporaryFile(\n",
    "                prefix='transition_parse.train',\n",
    "                dir=tempfile.gettempdir(),\n",
    "                delete=False)\n",
    "\n",
    "            if self._algorithm == self.ARC_STANDARD:\n",
    "                self._create_training_examples_arc_std(depgraphs, input_file)\n",
    "            else:\n",
    "                self._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "            input_file.close()\n",
    "            # Using the temporary file to train the libsvm classifier\n",
    "            x_train, y_train = load_svmlight_file(input_file.name)\n",
    "            if self.training_classifier == \"svm\" :\n",
    "                # The parameter is set according to the paper:\n",
    "                # Algorithms for Deterministic Incremental Dependency Parsing by Joakim Nivre\n",
    "                # Todo : because of probability = True => very slow due to\n",
    "                # cross-validation. Need to improve the speed here\n",
    "                model = svm.SVC(\n",
    "                    kernel='poly',\n",
    "                    degree=2,\n",
    "                    coef0=0,\n",
    "                    gamma=0.2,\n",
    "                    C=0.5,\n",
    "                    verbose=verbose,\n",
    "                    probability=True)\n",
    "            elif self.training_classifier == \"log\":\n",
    "                model = LogisticRegression(penalty='l2',\n",
    "                    dual=False, tol=0.0001, C=1.0,\n",
    "                    fit_intercept=True, intercept_scaling=1,\n",
    "                    class_weight=None, random_state=42, solver='liblinear',\n",
    "                    max_iter=100, multi_class='ovr', verbose=0, warm_start=False,\n",
    "                    n_jobs=1)\n",
    "            elif self.training_classifier == \"mlp\":\n",
    "                model = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                        hidden_layer_sizes=(100,50,25,), random_state=1)\n",
    "\n",
    "            model.fit(x_train, y_train)\n",
    "            # Save the model to file name (as pickle)\n",
    "            pickle.dump(model, open(modelfile, 'wb'))\n",
    "\n",
    "        finally:\n",
    "            remove(input_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training With original data (without column 10 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "train_data = DependencyGraph.load(BASE_TRAIN_FILE+EXTENTION)\n",
    "test_data = DependencyGraph.load(BASE_TEST_FILE+EXTENTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc-Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "parser_std_svm = CustomTransitionParser('arc-standard',\"svm\")\n",
    "parser_std_svm.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_svm = parser_std_svm.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_svm, test_data)\n",
    "arc_std_svm_1 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original (Without column 10)\n",
      "ARC-STANDARD, SVM :  (0.8624338624338624, 0.7709750566893424)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original (Without column 10)\")\n",
    "print(\"ARC-STANDARD, SVM : \",arc_std_svm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n"
     ]
    }
   ],
   "source": [
    "parser_std_log = CustomTransitionParser('arc-standard',\"log\")\n",
    "parser_std_log.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_log = parser_std_log.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_log, test_data)\n",
    "arc_std_log_1 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original (Without column 10)\n",
      "ARC-STANDARD, LOGISTIC REGRESSION :  (0.8034769463340892, 0.6893424036281179)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original (Without column 10)\")\n",
    "print(\"ARC-STANDARD, LOGISTIC REGRESSION : \",arc_std_log_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n"
     ]
    }
   ],
   "source": [
    "parser_std_mlp = CustomTransitionParser('arc-standard',\"mlp\")\n",
    "parser_std_mlp.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_mlp = parser_std_mlp.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_mlp, test_data)\n",
    "arc_std_mlp_1 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original (Without column 10)\n",
      "ARC-STANDARD, MLP :  (0.8261526832955405, 0.7150415721844293)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original (Without column 10)\")\n",
    "print(\"ARC-STANDARD, MLP : \",arc_std_mlp_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc-Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "parser_eag_svm = CustomTransitionParser('arc-eager',\"svm\")\n",
    "parser_eag_svm.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_svm = parser_eag_svm.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_svm, test_data)\n",
    "arc_eag_svm_1 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original (Without column 10)\n",
      "ARC-EAGER, SVM :  (0.8828420256991686, 0.7928949357520786)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original (Without column 10)\")\n",
    "print(\"ARC-EAGER, SVM : \",arc_eag_svm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n"
     ]
    }
   ],
   "source": [
    "parser_eag_log = CustomTransitionParser('arc-standard',\"log\")\n",
    "parser_eag_log.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_log = parser_std_log.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_log, test_data)\n",
    "arc_eag_log_1 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original (Without column 10)\n",
      "ARC-EAGER, LOGISTIC REGRESSION :  (0.8034769463340892, 0.6893424036281179)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original (Without column 10)\")\n",
    "print(\"ARC-EAGER, LOGISTIC REGRESSION : \",arc_eag_log_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 501\n",
      " Number of valid (projective) examples : 477\n"
     ]
    }
   ],
   "source": [
    "parser_eag_mlp = CustomTransitionParser('arc-standard',\"mlp\")\n",
    "parser_eag_mlp.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_mlp = parser_std_mlp.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_mlp, test_data)\n",
    "arc_eag_mlp_1 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original (Without column 10)\n",
      "ARC-EAGER, MLP :  (0.8261526832955405, 0.7150415721844293)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original (Without column 10)\")\n",
    "print(\"ARC-EAGER, MLP : \",arc_eag_mlp_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training With original data + column 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "train_data = DependencyGraph.load(BASE_TRAIN_FILE+EXTRA_SUFFIX+EXTENTION)\n",
    "test_data = DependencyGraph.load(BASE_TEST_FILE+EXTRA_SUFFIX+EXTENTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc-Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "parser_std_svm = CustomTransitionParser('arc-standard',\"svm\")\n",
    "parser_std_svm.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_svm = parser_std_svm.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_svm, test_data)\n",
    "arc_std_svm_2 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original + column 10\n",
      "ARC-STANDARD, SVM :  (0.9168556311413454, 0.8329554043839759)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original + column 10\")\n",
    "print(\"ARC-STANDARD, SVM : \",arc_std_svm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_std_log = CustomTransitionParser('arc-standard',\"log\")\n",
    "parser_std_log.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_log = parser_std_log.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_log, test_data)\n",
    "arc_std_log_2 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original + column 10\n",
      "ARC-STANDARD, LOGISTIC REGRESSION :  (0.873015873015873, 0.7755102040816326)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original + column 10\")\n",
    "print(\"ARC-STANDARD, LOGISTIC REGRESSION : \",arc_std_log_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_std_mlp = CustomTransitionParser('arc-standard',\"mlp\")\n",
    "parser_std_mlp.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_mlp = parser_std_mlp.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_mlp, test_data)\n",
    "arc_std_mlp_2 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original + column 10\n",
      "ARC-STANDARD, MLP :  (0.8820861678004536, 0.780045351473923)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original + column 10\")\n",
    "print(\"ARC-STANDARD, MLP : \",arc_std_mlp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc-Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "parser_eag_svm = CustomTransitionParser('arc-eager',\"svm\")\n",
    "parser_eag_svm.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_svm = parser_eag_svm.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_svm, test_data)\n",
    "arc_eag_svm_2 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original + column 10\n",
      "ARC-EAGER, SVM :  (0.9115646258503401, 0.8261526832955405)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original + column 10\")\n",
    "print(\"ARC-EAGER, SVM : \",arc_eag_svm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_eag_log = CustomTransitionParser('arc-standard',\"log\")\n",
    "parser_eag_log.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_log = parser_std_log.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_log, test_data)\n",
    "arc_eag_log_2 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original + column 10\n",
      "ARC-EAGER, LOGISTIC REGRESSION :  (0.873015873015873, 0.7755102040816326)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original + column 10\")\n",
    "print(\"ARC-EAGER, LOGISTIC REGRESSION : \",arc_eag_log_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_eag_mlp = CustomTransitionParser('arc-standard',\"mlp\")\n",
    "parser_eag_mlp.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_mlp = parser_std_mlp.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_mlp, test_data)\n",
    "arc_eag_mlp_2 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - Original + column 10\n",
      "ARC-EAGER, MLP :  (0.8820861678004536, 0.780045351473923)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - Original + column 10\")\n",
    "print(\"ARC-EAGER, MLP : \",arc_eag_mlp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Without MORPHOLOGICAL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/nltk/parse/dependencygraph.py:380: UserWarning: The graph doesn't contain a node that depends on the root element.\n",
      "  \"The graph doesn't contain a node \"\n"
     ]
    }
   ],
   "source": [
    "train_data = DependencyGraph.load(BASE_TRAIN_FILE+REMOVE_SUFFIX+EXTENTION)\n",
    "test_data = DependencyGraph.load(BASE_TEST_FILE+REMOVE_SUFFIX+EXTENTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc-Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "parser_std_svm = CustomTransitionParser('arc-standard',\"svm\")\n",
    "parser_std_svm.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_svm = parser_std_svm.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_svm, test_data)\n",
    "arc_std_svm_3 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - WITHOUT Morphological Features\n",
      "ARC-STANDARD, SVM :  (0.8495842781557067, 0.7664399092970522)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - WITHOUT Morphological Features\")\n",
    "print(\"ARC-STANDARD, SVM : \",arc_std_svm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_std_log = CustomTransitionParser('arc-standard',\"log\")\n",
    "parser_std_log.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_log = parser_std_log.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_log, test_data)\n",
    "arc_std_log_3 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - WITHOUT Morphological Features\n",
      "ARC-STANDARD, LOGISTIC REGRESSION :  (0.800453514739229, 0.6923658352229781)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - WITHOUT Morphological Features\")\n",
    "print(\"ARC-STANDARD, LOGISTIC REGRESSION : \",arc_std_log_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_std_mlp = CustomTransitionParser('arc-standard',\"mlp\")\n",
    "parser_std_mlp.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_std_mlp = parser_std_mlp.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_std_mlp, test_data)\n",
    "arc_std_mlp_3 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - WITHOUT Morphological Features\n",
      "ARC-STANDARD, MLP :  (0.8065003779289494, 0.6969009826152683)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - WITHOUT Morphological Features\")\n",
    "print(\"ARC-STANDARD, MLP : \",arc_std_mlp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arc-Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "parser_eag_svm = CustomTransitionParser('arc-eager',\"svm\")\n",
    "parser_eag_svm.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_svm = parser_eag_svm.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_svm, test_data)\n",
    "arc_eag_svm_3 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - WITHOUT Morphological Features\n",
      "ARC-EAGER, SVM :  (0.8692365835222978, 0.7724867724867724)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - WITHOUT Morphological Features\")\n",
    "print(\"ARC-EAGER, SVM : \",arc_eag_svm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_eag_log = CustomTransitionParser('arc-standard',\"log\")\n",
    "parser_eag_log.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_log = parser_std_log.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_log, test_data)\n",
    "arc_eag_log_3 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - WITHOUT Morphological Features\n",
      "ARC-EAGER, LOGISTIC REGRESSION :  (0.800453514739229, 0.6923658352229781)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - WITHOUT Morphological Features\")\n",
    "print(\"ARC-EAGER, LOGISTIC REGRESSION : \",arc_eag_log_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 502\n",
      " Number of valid (projective) examples : 478\n"
     ]
    }
   ],
   "source": [
    "parser_eag_mlp = CustomTransitionParser('arc-standard',\"mlp\")\n",
    "parser_eag_mlp.train(train_data,'temp.arcstd.model',verbose=True)\n",
    "result_eag_mlp = parser_std_mlp.parse(test_data, 'temp.arcstd.model')\n",
    "de = DependencyEvaluator(result_eag_mlp, test_data)\n",
    "arc_eag_mlp_3 = de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET - WITHOUT Morphological Features\n",
      "ARC-EAGER, MLP :  (0.8065003779289494, 0.6969009826152683)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET - WITHOUT Morphological Features\")\n",
    "print(\"ARC-EAGER, MLP : \",arc_eag_mlp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
